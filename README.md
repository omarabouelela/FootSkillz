# FootSkillz
Project: Football Skill Classification from IMU Sensors

Project Description

This project builds a machine-learning pipeline to classify football skills using data from wearable IMU sensors (Accelerometer, Gyroscope, and Gravity).

The player performs four football skills:

* Heading
* Juggling
* Pass
* Shots

Each skill is recorded multiple times. For every recording, raw IMU signals are:

1. Preprocessed and cleaned
2. Pause segments removed (player standing still before starting the skill)
3. Segmented into overlapping windows
4. Outliers removed / smoothed
5. Transformed into feature vectors
6. Used to train and evaluate multiple ML models

The goal is to automatically detect the type of football skill being performed based on the sensor signals.

Dataset Structure

The raw recordings are stored as a single archive: readings.zip
Each recording is a zipped folder containing CSV files for each sensor.

1. Raw data (readings.zip)

Inside readings.zip:

readings/
├─ Heading/
│   ├─ a.zip
│   ├─ b.zip
│   └─ ...
├─ Juggling/
├─ Pass/
└─ Shots/

Each *.zip contains:

sample_x/
├─ Accelerometer.csv
├─ Gyroscope.csv
└─ Gravity.csv

Each CSV has (at least):

* seconds_elapsed or time
* x, y, z sensor axes

2. Preprocessing output (preprocessing/)

Generated by Stage 1 script (pause removal, cleaning, windowing):

preprocessing/
├─ Heading/
│   ├─ a/
│   │   ├─ win_000_acc.csv
│   │   ├─ win_000_gyro.csv
│   │   ├─ win_000_grav.csv
│   │   ├─ win_001_acc.csv
│   │   └─ ...
│   └─ b/
├─ Juggling/
├─ Pass/
├─ Shots/
└─ windows_metadata.csv

Each win_XXX_*.csv = one cleaned time window of data for that sensor:

* Columns: t, x, y, z

windows_metadata.csv describes every window:

* skill, recording, window_id
* start_time, end_time
* n_samples, fs
* pause_time (trimmed idle time before the skill)

3. Feature extraction output (features/)

Generated by Stage 2 scripts:

features/
├─ features_all_windows.csv
└─ features_balanced_windows.csv

For each window and each sensor (Acc / Gyro / Grav, axes x/y/z and magnitude), the following features are computed:

* Mean
* Standard deviation
* 2nd central moment (*_mom2)
* 3rd central moment (*_mom3)
* Kurtosis (*_kurtosis)
* Zero-crossing rate (*_zcr)

features_balanced_windows.csv is an under-sampled version where all four skills have the same number of windows (balanced classes), ready for model training.

4. Model scripts (models/)

Each model script reads features_balanced_windows.csv, trains a classifier, and prints metrics:

* Logistic Regression
* Decision Tree
* Random Forest
* K-Nearest Neighbors (KNN)
* Naive Bayes (GaussianNB)
* XGBoost
* LightGBM
* Linear Discriminant Analysis (LDA)
* Quadratic Discriminant Analysis (QDA)
* CatBoost
* AdaBoost
* SVM (RBF kernel)

Example file structure:

models/
├─ stage1_preprocess.py
├─ stage2_features.py
├─ stage2b_balance_windows.py
├─ stage3_model1_logistic_regression.py
├─ stage3_model2_decision_tree.py
├─ stage3_model3_random_forest.py
├─ stage3_model4_knn.py
├─ stage3_model5_naive_bayes.py
├─ stage3_model6_xgboost.py
├─ stage3_model7_lightgbm.py
├─ stage3_model8_lda.py
├─ stage3_model9_catboost.py
├─ stage3_model10_qda.py
├─ stage3_model11_adaboost.py
└─ stage3_model12_svm.py

How to Run

1. Requirements

Python 3.10+ (tested with Python 3.11)

Install dependencies (minimal set):

pip install numpy pandas scikit-learn xgboost lightgbm catboost

(Optional, for plotting if needed):

pip install matplotlib

2. Stage 1 – Preprocessing and Windowing

From the project root (where readings.zip is located):

python models/stage1_preprocess.py

This will:

* Read readings.zip
* Load Accelerometer/Gyroscope/Gravity CSVs
* Detect and remove pause time (pre-skill idle segment)
* Clean spikes/outliers in signals
* Segment post-pause data into overlapping windows (e.g. 2 s window, 1 s step)
* Save per-window CSVs in preprocessing/
* Generate preprocessing/windows_metadata.csv

3. Stage 2 – Feature Extraction

Compute features for every window:

python models/stage2_features.py

This will:

* Read preprocessing/windows_metadata.csv and all win_XXX_*.csv files
* Extract mean, std, moments, kurtosis, and zero-crossing rate
* Save features into features/features_all_windows.csv

Then balance the classes (under-sampling):

python models/stage2b_balance_windows.py

This will:

* Read features/features_all_windows.csv
* Under-sample each skill to the same number of windows
* Shuffle and save balanced dataset as:
  features/features_balanced_windows.csv

This is the main ML input file for training.

4. Stage 3 – Training Models

Each model script:

* Reads features/features_balanced_windows.csv
* Splits into train/test (80/20, stratified)
* Uses a Pipeline:
  SimpleImputer (median) -> StandardScaler -> classifier
* Runs 5-fold cross-validation
* Trains on training set
* Evaluates on test set
* Prints:

  * Cross-validation accuracies (per fold and mean ± std)
  * Test accuracy
  * Classification report
  * Confusion matrix
  * Training time
  * Inference time per sample

Example:

Logistic Regression:
python models/stage3_model1_logistic_regression.py

Random Forest:
python models/stage3_model3_random_forest.py

SVM:
python models/stage3_model12_svm.py

…and similarly for the other model scripts.


Hardware Requirements

This project is lightweight and can run on a standard laptop.

The experiments were run on:

* CPU: 13th Gen Intel(R) Core(TM) i7-13700HX @ 2.10 GHz
* RAM: 16.0 GB (15.8 GB usable)
* GPU: Not required (all models run on CPU)

Typical usage:

* Preprocessing and feature extraction: fast (small dataset).
* Training all models: runs comfortably on CPU within seconds to a few minutes.

Minimum recommended hardware:

* CPU with at least 4 cores
* 8 GB RAM

Tested configuration:

* 16 GB RAM
* 13th Gen i7-13700HX
* No performance issues observed.

Training Steps (Summary)

1. Raw data collection

* IMU sensors (Accelerometer, Gyroscope, Gravity) record time-series data while the player performs:

  * Heading
  * Juggling
  * Pass
  * Shots
* Each recording is saved as a zipped folder of CSV files.

2. Stage 1 – Preprocessing and windowing

* Load each recording and standardize time (seconds_elapsed/time -> t starting from 0).
* Compute magnitude of each sensor.
* Detect pause region using a rolling RMS threshold on accelerometer magnitude.
* Trim pause and keep only the active skill segment.
* Clean outliers (spikes) using robust statistics.
* Apply overlapping windowing (e.g. 2 s windows, 1 s step).
* Save each window as a separate CSV for Acc/Gyro/Grav.
* Log all windows in windows_metadata.csv.

3. Stage 2 – Feature extraction

* For each window and each sensor axis / magnitude:

  * Mean
  * Standard deviation
  * 2nd and 3rd central moments
  * Kurtosis
  * Zero-crossing rate
* Save features into features_all_windows.csv.
* Under-sample each class to balance the dataset, saving features_balanced_windows.csv.

4. Stage 3 – Model training and evaluation
   For each model (Logistic Regression, Decision Tree, Random Forest, KNN, Naive Bayes, XGBoost, LightGBM, LDA, QDA, CatBoost, AdaBoost, SVM):

* Load features_balanced_windows.csv.
* Encode skill labels as integers.
* Train/test split (80/20, stratified).
* Build a pipeline: Impute -> Scale -> Classifier.
* Perform 5-fold cross-validation.
* Train on training set and evaluate on test set.
* Report:

  * Cross-validation accuracy
  * Test accuracy
  * Confusion matrix and classification report
  * Training time
  * Inference time (total and per sample)

Done By:

Omar Abouelela
dept. of Electronics & Communication
College of Engineering & tech., AASTMT
Alexandria, Egypt
O.Ela0052@student.aast.edu

Ismail Kassem
dept. of Electronics & Communication
College of Engineering & tech., AASTMT
Alexandria, Egypt
I.Kassem0082@student.aast.edu 

Omar Sherif
dept. of Electronics & Communication
College of Engineering & tech., AASTMT
Alexandria, Egypt
O.Moussa0082@student.aast.edu

Ahmed Samy
dept. of Electronics & Communication
College of Engineering & tech., AASTMT
Alexandria, Egypt
A.Fadl0354@student.aast.edu 

Mazen Mohab
dept. of Electronics & Communication
College of Engineering & tech., AASTMT
Alexandria, Egypt
M.Ammar0190@student.aast.edu

Omar Hossam
dept. of Electronics & Communication
College of Engineering & tech., AASTMT
Alexandria, Egypt
0.Farag0352@student.aast.edu 


